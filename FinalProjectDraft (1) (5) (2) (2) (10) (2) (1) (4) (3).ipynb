{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c25a22-8848-4bab-b5b4-3c07f123b01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.14.6\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 KB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.14.5\n",
      "    Uninstalling numpy-1.14.5:\n",
      "      Successfully uninstalled numpy-1.14.5\n",
      "Successfully installed joblib-1.1.0 numpy-1.21.6 scikit-learn-1.0.2 scipy-1.7.3 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6a01bb8-41a7-424b-9170-a5d6f9a0b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.3.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179ba6b-0df1-462f-aac3-cba018c0e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a model relating all of the features in the https://www.kaggle.com/datasets/brsdincer/star-type-classification set\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Make a \"summary\" of the features in the dataset\n",
    "1. Accuracy of model(s)\n",
    "    a. Temperature + Luminosity, T + L + R, T + L + R + M, L + R + M -> a. color (Red, Blue White, White, Yellowish, Pale yellow orange, Blue, Whitish, Yellow-White, Orange, Orange-Red,)\n",
    "2. Temperature, Luminosity ranges for each color\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7718d86a-6bf7-496a-8213-df6620d6793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e110b833-400c-457c-9c0e-43d4f15d44ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING MODELS\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Accuracy Score of KNN (Temperature+Luminosity->Color) is 0.75\n",
      "Accuracy Score of KNN (Temperature->Color) is 0.7708333333333334\n",
      "Accuracy Score of KNN (Luminosity->Color) is 0.6458333333333334\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Accuracy Score of Random Forest (Temperature+Luminosity->Color) is 0.875\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Accuracy Score of Decision Tree (Temperature+Luminosity->Color) is 0.7708333333333334\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Accuracy Score of Random Forest (Temperature->Color) is 0.6666666666666666\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Accuracy Score of Random Forest (Luminosity->Color) is 0.625\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Accuracy Score of Random Forest (Temperature+Luminosity+Radius->Color) is 0.8541666666666666\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Accuracy Score of Random Forest (Temperature+Luminosity+Radius+Absolute Magnitude->Color) is 0.8541666666666666\n",
      "------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "og_df = pd.DataFrame(pd.read_csv('Stars.csv'))\n",
    "\n",
    "\"\"\"\n",
    "The Color feature of the dataset had a lot of colors that were essentially the same but used different names\n",
    "This next part is where I went and made all the colors similar to each other have the same name\n",
    "\"\"\"\n",
    "#Change colors related to yellow and white to Yellowish White\n",
    "og_df = og_df.replace(to_replace=\"White Yellow\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"Yellowish\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"White-Yellow\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"White Yellow\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"Whitish\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"White\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"white Yellow\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"yellowish\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"white\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"yellow-white\", value=\"Yellowish White\")\n",
    "#Change colors related to orange to Orange\n",
    "og_df = og_df.replace(to_replace=\"Pale yellow orange\", value=\"Orange\")\n",
    "og_df = og_df.replace(to_replace=\"Orange-Red\", value=\"Orange\")\n",
    "#Change Blue-white to Blue White\n",
    "og_df = og_df.replace(to_replace=\"Blue-white\", value=\"Blue White\")\n",
    "og_df = og_df.replace(to_replace=\"Blue-White\", value=\"Blue White\")\n",
    "\n",
    "\"\"\"\n",
    "I create dataframes with the features I intend on using\n",
    "I turn the color dataframe to a NumPy array so I can use .ravel(), which changes the shape of the dataframe to suit the Machine Learning Models\n",
    "\"\"\"\n",
    "T = og_df[['Temperature']].copy()\n",
    "L = og_df[['L']].copy()\n",
    "color = og_df[['Color']].copy()\n",
    "color = color.to_numpy()\n",
    "radius = og_df[['R']].copy()\n",
    "absolute_magnitude = og_df[['A_M']].copy()\n",
    "\n",
    "\"\"\"\n",
    "I use .train_test_split() to create the train and test sets for the features I intended on using: Temperature, Luminosity (L)*, Relative Radius (R)*, Absolute Magnitude (A_M), and color\n",
    "I then make the dataframes that have the combination of the features I want to use to predict the color\n",
    "\n",
    "If the beginning of the variable name has:\n",
    "TL - Combination of Temperature and Luminosity\n",
    "TLR - Combination of Temperature, Luminosity, and Relative Radius\n",
    "TLRA - Combination of Temperature, Luminosity, Relative Radius, and Absolute Magnitude\n",
    "\n",
    "If the variable name has 'C' after the letters above, it refers to the Machine Learning model created\n",
    "\n",
    "\n",
    "*Luminosity and Radius here are relative to the Sun\n",
    "\"\"\"\n",
    "temp_train, temp_test, l_train, l_test, color_train, color_test, radi_train, radi_test, mag_train, mag_test= train_test_split(T, L, color, radius, absolute_magnitude, test_size = 0.2)\n",
    "TL_train = pd.concat([temp_train, l_train], axis=1)\n",
    "TL_test = pd.concat([temp_test, l_test], axis=1)\n",
    "TLR_train = pd.concat([temp_train, l_train, radi_train], axis=1)\n",
    "TLR_test = pd.concat([temp_test, l_test, radi_test], axis=1)\n",
    "TLRA_train = pd.concat([temp_train, l_train, radi_train, mag_train], axis=1)\n",
    "TLRA_test = pd.concat([temp_test, l_test, radi_test, mag_test], axis=1)\n",
    "\n",
    "color_train = color_train.ravel()\n",
    "\n",
    "\"\"\"\n",
    "Before comparing the features, I had to find the best model to use\n",
    "I trid K Nearest Neighbors first, but the accuracy of the model was lower than anticipated\n",
    "The Random Forest model yielded a much better accuracy\n",
    "The Decision Tree model was better than KNN, but not as good as Random Forest*\n",
    "\n",
    "*This is most likely because the Random Forest Machine Learning Model utilizes multiple Decision Trees within its algorithm, making it a more refined version of it\n",
    "\"\"\"\n",
    "print(\"TESTING MODELS\")\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "#Testing different models, K Nearest Neighbors\n",
    "n=8\n",
    "TLC = KNeighborsClassifier(n_neighbors = n)\n",
    "TLC.fit(TL_train, color_train)\n",
    "TLC_pre = TLC.predict(TL_test)\n",
    "\n",
    "print(\"Accuracy Score of KNN (Temperature+Luminosity->Color) is {}\".format(accuracy_score(color_test, TLC_pre)))\n",
    "\n",
    "\"\"\"\n",
    "Before trying other models, I wanted to make sure that the low accuracy score wasn't due to the data (as in the star's temperature and luminosity didn't correlate with\n",
    "its color), so I tried the KNN model with just Temperature and Luminosity. Both models were at about the same accuracy, or lower, so I knew the problem was with the model.\n",
    "It was here that I discoverd I initially made a mistake with the replace statements I used earlier, and was able to clean up the data properly.\n",
    "\"\"\"\n",
    "TC = KNeighborsClassifier(n_neighbors = n)\n",
    "TC.fit(temp_train, color_train)\n",
    "TC_pre = TC.predict(temp_test)\n",
    "\n",
    "print(\"Accuracy Score of KNN (Temperature->Color) is {}\".format(accuracy_score(color_test, TC_pre)))\n",
    "\n",
    "LC = KNeighborsClassifier(n_neighbors = n)\n",
    "LC.fit(l_train, color_train)\n",
    "LC_pre = LC.predict(l_test)\n",
    "\n",
    "print(\"Accuracy Score of KNN (Luminosity->Color) is {}\".format(accuracy_score(color_test,LC_pre)))\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# Testing Random Forest\n",
    "rTLC = RandomForestClassifier(max_depth = 4)\n",
    "rTLC.fit(TL_train, color_train)\n",
    "rTLC_pre = rTLC.predict(TL_test)\n",
    "\n",
    "print(\"Accuracy Score of Random Forest (Temperature+Luminosity->Color) is {}\".format(accuracy_score(color_test, rTLC_pre)))\n",
    "\"\"\"\n",
    "The accuracy ranges of the Random Forest Model are at a nice level, from 0.8 - 0.95. I decided to try one more model to see if I could improve the accuracy.\n",
    "\"\"\"\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "# Trying Decision Tree\n",
    "dTLC = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "dTLC.fit(TL_train, color_train)\n",
    "dTLC_pre = dTLC.predict(TL_test)\n",
    "\n",
    "print(\"Accuracy Score of Decision Tree (Temperature+Luminosity->Color) is {}\".format(accuracy_score(color_test, dTLC_pre)))\n",
    "\n",
    "\"\"\"\n",
    "The accuracy of the Decision Tree model was lower than that of the Random Forest, from 0.75 - 0.85. This makes sense, as I learned later that the\n",
    "Random Forest algorithm uses mulitple Decision Trees, hence the name forest. So there was a high chance of this model having a lower accuracy than\n",
    "that of the Random Forest.\n",
    "\"\"\"\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "\"\"\"\n",
    "With the model decided, I wanted to check the relationships between different features of a star and it's color.\n",
    "I started by testing models that only use Temperature and only use Luminosity, and added on the Relative Radius and Absolute Magnitude to see if they\n",
    "had an affect on the accuracy. \n",
    "\"\"\"\n",
    "\n",
    "rTC = RandomForestClassifier(max_depth = 4)\n",
    "rTC.fit(temp_train, color_train)\n",
    "rTC_pre = rTC.predict(temp_test)\n",
    "\n",
    "print(\"Accuracy Score of Random Forest (Temperature->Color) is {}\".format(accuracy_score(color_test, rTC_pre)))\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "rLC = RandomForestClassifier(max_depth = 4)\n",
    "rLC.fit(l_train, color_train)\n",
    "rLC_pre = rLC.predict(l_test)\n",
    "\n",
    "print(\"Accuracy Score of Random Forest (Luminosity->Color) is {}\".format(accuracy_score(color_test,rLC_pre)))\n",
    "\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "\"\"\"\n",
    "With the accuracy of the Temperature and Luminosity solo models being lower than the model which included both, I started to add Relative Radius to the \n",
    "model to see its effect.\n",
    "\"\"\"\n",
    "\n",
    "rTLRC = RandomForestClassifier(max_depth = 4)\n",
    "rTLRC.fit(TLR_train, color_train)\n",
    "rTLRC_pre = rTLRC.predict(TLR_test)\n",
    "\n",
    "print(\"Accuracy Score of Random Forest (Temperature+Luminosity+Radius->Color) is {}\".format(accuracy_score(color_test, rTLRC_pre)))\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "\"\"\"\n",
    "The model with Temperature, Luminosity, and Relative Radius had an accuracy of about 87.5 - 98, so I believe the relative radius of a star had a slight effect on its color.\n",
    "With that completed, I added Absolute Magnitude to the model to see if that had any effect.\n",
    "\"\"\"\n",
    "rTLRAC = RandomForestClassifier(max_depth = 4)\n",
    "rTLRAC.fit(TLRA_train, color_train)\n",
    "rTLRAC_pre = rTLRAC.predict(TLRA_test)\n",
    "\n",
    "print(\"Accuracy Score of Random Forest (Temperature+Luminosity+Radius+Absolute Magnitude->Color) is {}\".format(accuracy_score(color_test, rTLRAC_pre)))\n",
    "\n",
    "\"\"\"\n",
    "The model with Absolute Magnitude included with Temperature, Luminosity, and Relative Radius had an accuracy that was usually lower than that of the model without it, sometimes\n",
    "equal, and rarely higher. So I conclude that Absolute Magnitude doesn't have an effect on a star's color.\n",
    "\"\"\"\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390fd38-c50a-4187-9492-19c03a10886c",
   "metadata": {},
   "source": [
    "Problems I Faced:\n",
    "\n",
    "Problem 1:\n",
    "\n",
    "I faced my first problem when I was starting to test out the models. I couldn't get any of them to work because of an error where the .fit() method was expecting 1d array but an array with a different shape was passed. I searched up the error on stackoverflow and saw the solution was in the method .ravel(). The .ravel() method changes the shape of a NumPy array to be 1d.\n",
    "\n",
    "The error message I encountered: \"DataConversionWarning: A column-vector y was passed when a 1d array was expected.\"\n",
    "\n",
    "Problem 2:\n",
    "\n",
    "After the KNN models weren't as accurate as I had hoped, and after I found out that the problem wasn't with how well the temperature and luminosity features correlated with color, I displayed the different train and test sets to see if the problem lay in the data. It turns out that the .replace() functions I was previously using weren't doing what they were supposed to, and the train and test sets still had to deal with weirdly named colors. I checked on stackoverflow and the Pandas documentation, and it turns out I was using them wrong. I had to set the dataframe equal to itself after I replaced the color names.\n",
    "\n",
    "What I was doing before: og_df.replace(to_replace=\"Blue-White\", value=\"Blue White\")\n",
    "\n",
    "What I had to do: og_df = og_df.replace(to_replace=\"Blue-White\", value=\"Blue White\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
